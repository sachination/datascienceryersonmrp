{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.dates import DateFormatter\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetime_range(start, end, delta):\n",
    "    current = start\n",
    "    while current < end:\n",
    "        yield current\n",
    "        current += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'C:/Users/jainsac/Downloads/MRP/Assignment 2/'\n",
    "RootFilePath = r'C:/Users/jainsac/Downloads/MRP/Assignment 2/Layer1Data/Output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jainsac\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Reading the file\n",
    "channelData = pd.concat(map(lambda file: pd.read_csv(file, header = 0 , sep ='\\t', index_col=0), glob.glob(os.path.join('', path+'Layer1Data/*.csv'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channelData['scan_time'] = pd.to_datetime(channelData['scan_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_list = channelData.channel_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56334, 56340, 56341, 56342, 56343]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List provided by Sami\n",
    "channel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = r'C:/Users/jainsac/Downloads/MRP/Assignment 2/'\n",
    "\n",
    "# Reading all the channel data files and loading\n",
    "# them in channelData dataframe. channelData data\n",
    "# frame contains following attributes: scan_time, \n",
    "# channel_id, power_dbm\n",
    "#allFiles = glob.glob(path+'/channels*.p')\n",
    "#channelData = pd.concat((pickle.load(open(f, \"rb\")) for f in allFiles))\n",
    "\n",
    "year = 2016\n",
    "month = 10\n",
    "\n",
    "# Reading the timerange file and loading\n",
    "# them in timeRange data frame\n",
    "ranges = glob.glob(path+'/time*.p')\n",
    "timeRange = pd.concat((pickle.load(open(f, \"rb\")) for f in ranges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dts = [dt.strftime('%Y-%m-%d %H:%M:%S.%f ') for dt in \n",
    "       datetime_range(datetime(year, month, 1, 0, 0, 0, 0), datetime(year, month, 31, 0, 0, 0, 0), \n",
    "                      timedelta(minutes=30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code below takes the subset of the data from channel and\n",
    "# time range and aggregate the value of occupancy for each time interval\n",
    "# in the end list of occupancy and start time values are saved into temp_df dataframe\n",
    "for ch in channel_list:\n",
    "    #print('Channel: '+str(ch))\n",
    "    i = 0\n",
    "    j = 1\n",
    "    a_list = []\n",
    "    b_list = []\n",
    "    end_list = []\n",
    "    while (i < len(dts) and j < len(dts)):\n",
    "        channel = ch\n",
    "        startTime = dts[i]\n",
    "        endTime = dts[j]\n",
    "        #print('Value of i: '+str(i))\n",
    "        #print('Value of j: '+str(j))\n",
    "\n",
    "        #print('Start Time:' +startTime)\n",
    "        #print('End Time: '+ endTime)\n",
    "        chanMask = channelData.channel_id == channel\n",
    "        #print('Chanmask')\n",
    "        #print(chanMask.head())\n",
    "        \n",
    "        #print('Timemask')\n",
    "        timeMask = (channelData.scan_time > startTime) & (channelData.scan_time <= endTime)\n",
    "        #print(timeMask.head())\n",
    "        \n",
    "        #print('Subset')\n",
    "        subset = channelData.loc[chanMask & timeMask].reset_index(drop = True)\n",
    "        #print(subset.head())\n",
    "        #print('Subset length: '+str(ch)+': '+str(len(subset)))\n",
    "\n",
    "        timeMask2 = (timeRange.scan_time > startTime) & (timeRange.scan_time <= endTime)\n",
    "        subTimeRange = timeRange.loc[timeMask2].reset_index(drop = True)\n",
    "        #print(subTimeRange.head())\n",
    "        #print('Subtime Range length: '+str(ch)+': '+str(len(subTimeRange)))\n",
    "\n",
    "        if (len(subset) and len(subTimeRange)) > 0:\n",
    "            merged = pd.merge(left = subTimeRange, right = subset, how = 'left')\n",
    "            merged = merged.fillna(value = {'channel_id': channel})\n",
    "            \n",
    "            #condition: pd.isnull(merged.power_dbm)\n",
    "            #when condition is true value is 1 else 0\n",
    "            merged['isEmpty'] = np.where(pd.isnull(merged.power_dbm), 1, 0)\n",
    "            \n",
    "            #print(1-sum(merged.isEmpty))\n",
    "            #print(merged.shape[0])\n",
    "            \n",
    "            OccPercent = 1-sum(merged.isEmpty)/merged.shape[0]\n",
    "            a_list.append(startTime)\n",
    "            b_list.append(OccPercent*100)\n",
    "            end_list.append(endTime)\n",
    "        i = i+1\n",
    "        j = j+1\n",
    "\n",
    "    temp_df = pd.DataFrame({'Channel': ch, 'StartTime': a_list, 'EndTime': end_list, 'Occupancy': b_list}, columns=['StartTime', 'EndTime', 'Channel', 'Occupancy']) \n",
    "    #writer = pd.ExcelWriter(RootFilePath+'30MinOutput'+str(ch)+'.xlsx')\n",
    "#    temp_df.to_excel(writer,'Sheet1', index=False)\n",
    "    temp_df.to_csv(RootFilePath + str(ch)+'.csv', sep='\\t', index=False)\n",
    "    #writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
