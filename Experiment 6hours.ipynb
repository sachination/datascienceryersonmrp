{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import datetime as dt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read layer3-60 data from all the csv files \n",
    "path = r'C:/Users/jainsac/Downloads/MRP/Assignment 2/Data/Oct30min/'\n",
    "Resultpath = r'C:/Users/jainsac/Downloads/MRP/Assignment 2/Results/'\n",
    "data = pd.concat(map(lambda file: pd.read_csv(file, header = 0,sep='\\t', encoding='utf-8'), glob.glob(os.path.join('', path+'/*.csv'))))\n",
    "#data.columns = ['StartTime', 'EndTime', 'Channel', 'Power_dbm','SNR', 'Occupancy']\n",
    "data.columns = ['StartTime', 'EndTime', 'Channel', 'Occupancy']\n",
    "data['StartTime'] = pd.to_datetime(data['StartTime'])\n",
    "data['EndTime'] = pd.to_datetime(data['EndTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01 05:00:00</td>\n",
       "      <td>2016-10-01 05:30:00</td>\n",
       "      <td>10670</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01 05:30:00</td>\n",
       "      <td>2016-10-01 06:00:00</td>\n",
       "      <td>10670</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01 06:00:00</td>\n",
       "      <td>2016-10-01 06:30:00</td>\n",
       "      <td>10670</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01 06:30:00</td>\n",
       "      <td>2016-10-01 07:00:00</td>\n",
       "      <td>10670</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01 07:00:00</td>\n",
       "      <td>2016-10-01 07:30:00</td>\n",
       "      <td>10670</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StartTime             EndTime  Channel  Occupancy\n",
       "0 2016-10-01 05:00:00 2016-10-01 05:30:00    10670      100.0\n",
       "1 2016-10-01 05:30:00 2016-10-01 06:00:00    10670      100.0\n",
       "2 2016-10-01 06:00:00 2016-10-01 06:30:00    10670      100.0\n",
       "3 2016-10-01 06:30:00 2016-10-01 07:00:00    10670      100.0\n",
       "4 2016-10-01 07:00:00 2016-10-01 07:30:00    10670      100.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chList = pd.read_csv('C:/Users/jainsac/Downloads/MRP/Assignment 2/ChannelList.csv', header=0, sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_list = chList.Channel.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#channel_list = [16010, 15820, 15540, 15530, 15570, 22490, 23480, 21340, 24220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of channels will override the final list until entire data is available\n",
    "channel_list = [16010, 15820, 15540, 15530, 15570, 22490, 23480, 21340, 24220, 16130, 24670, 24890, 25410, 25810, 24530,26030, 29310, 28150,\n",
    "                31020, 27710, 34700, 50132, 50193, 31780, 50175, 50271, 50280, 50269, 50259, 50285, 50309, 50617, 50361, 50295, 50287, 50659, \n",
    "                50677, 51028, 50673, 51085, 51095, 51119, 51111, 51224, 51086, 53112, 51292, 51272, 53236, 53144, 10670, 11720, 11710, 10930, \n",
    "                2340, 15420, 15990, 50969, 12040, 29990, 11870, 15220, 15130, 13300, 13520, 51366, 53334, 53333, 51176, 51026, 54494, 53970, \n",
    "                53379, 54006, 53442, 54620, 56303, 56304, 56293, 56097, 56305, 56306, 56307, 56308, 56333, 56350, 56352, 56353, 56354, 56355, \n",
    "                56360, 56356, 56357, 56358, 56359, 1370, 3860, 830, 2020, 131, 11830, 11840, 11860, 9230, 11800, 55232, 55240, 55292, 55293,\n",
    "                55338, 55355, 55361, 55372, 55410, 55417, 55457, 55481, 55482, 55508, 55510, 55520, 55639, 55640, 55678, 55692, 55713, 55797,\n",
    "                55858, 55902, 55920, 55922, 56033, 56181, 56230, 56232, 56283, 56294, 56295, 56296, 56300, 56301, 56322, 56323, 56324, 56325,\n",
    "                56334, 56340, 56341, 56342, 56343\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TimeInducedDfOriginal = merged\n",
    "\n",
    "TimeInducedDfOriginal = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TimeInducedDf = TimeInducedDfOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pValue = []\n",
    "#for fr in thresh_list:\n",
    "fr = 80\n",
    "for ch in channel_list:\n",
    "    #print(ch)\n",
    "    #print(fr)\n",
    "\n",
    "\n",
    "    TimeInducedDf = TimeInducedDfOriginal[(TimeInducedDfOriginal.Channel == ch)][['StartTime', 'EndTime', 'Channel', 'Occupancy']]\n",
    "    TimeInducedDf['StartTimeIndex'] = TimeInducedDf['StartTime'].values.astype('<M8[m]')\n",
    "    TimeInducedDf['EndTimeStrip'] = TimeInducedDf['EndTime'].values.astype('<M8[m]')\n",
    "    TimeInducedDf = TimeInducedDf.drop(['StartTime', 'EndTime'], 1)\n",
    "    TimeInducedDf = TimeInducedDf[[ 'Channel','StartTimeIndex', 'EndTimeStrip','Occupancy']]\n",
    "    TimeInducedDf = TimeInducedDf.set_index('StartTimeIndex')\n",
    "    TimeInducedDf= TimeInducedDf.reindex(pd.date_range(start=TimeInducedDf.index[0], end=TimeInducedDf.index[-1], freq='6h'))\n",
    "    TimeInducedDf[TimeInducedDf['Occupancy'].isnull()]\n",
    "    k = 2\n",
    "    TimeInducedDf['T1'] = TimeInducedDf['Occupancy'].shift()\n",
    "    while k <=6:\n",
    "        TimeInducedDf['T'+str(k)] = TimeInducedDf['T'+str(k-1)].shift()\n",
    "        k=k+1\n",
    "    # Convert index back to dataframe column\n",
    "    TimeInducedDf.reset_index(level=0, inplace=True)\n",
    "\n",
    "    # Remove NAs\n",
    "    TimeInducedDf = TimeInducedDf.dropna(subset=['Occupancy', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6'], how='any')\n",
    "    TimeInducedDf['OccupancyClass'] = pd.cut(TimeInducedDf['Occupancy'], [-np.inf, fr, np.inf], labels=[0, 1])\n",
    "\n",
    "    TimeInducedDFy = TimeInducedDf[(TimeInducedDf.Channel == ch)][['OccupancyClass']] \n",
    "    t = TimeInducedDFy.groupby('OccupancyClass').size()\n",
    "    if (t[0] > 5 and t[1] > 5):\n",
    "        LRaccuracy = []\n",
    "        LRsensitivity = []\n",
    "        LRspecificity = []\n",
    "        LRfmeasure = []\n",
    "        LRprecision = []\n",
    "        NBaccuracy = []\n",
    "        NBsensitivity = []\n",
    "        NBspecificity = []\n",
    "        NBfmeasure = []\n",
    "        NBprecision = []\n",
    "        FoldCount = []\n",
    "        NumCount = []\n",
    "        channelNum = []\n",
    "        Threshold = []\n",
    "        # split the dataframe into two sets: x - attributes, y - response variables\n",
    "        # in our case, y = Occupancy, x would be rest of the columns\n",
    "        TimeInducedDFx = TimeInducedDf[(TimeInducedDf.Channel == ch)][['Channel', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6']]\n",
    "\n",
    "        # Insert a while loop to averager out the runs. value of numofruns = 10\n",
    "        numOfRuns = 1\n",
    "        while numOfRuns <= 10:\n",
    "\n",
    "            numOfSplits = 10   \n",
    "            # initialize variables for each channel\n",
    "            n = len(TimeInducedDFx)\n",
    "            fold = 0\n",
    "            #for trainRatio in np.arange(0.05, 1, 0.05):\n",
    "            kf = KFold(n_splits = numOfSplits, shuffle=True, random_state = 777)\n",
    "            for train_idx, test_idx in kf.split(TimeInducedDFx, TimeInducedDFy):\n",
    "                X_trainNew, X_testNew = TimeInducedDFx.iloc[train_idx], TimeInducedDFx.iloc[test_idx]\n",
    "                y_trainNew, y_testNew = TimeInducedDFy.iloc[train_idx], TimeInducedDFy.iloc[test_idx]\n",
    "\n",
    "                # check if values in y_train are more than 1. \n",
    "                # if len(y_trainNew.OccupancyClass.unique()) > 1:\n",
    "                fold += 1\n",
    "                FoldCount.append(fold)\n",
    "                NumCount.append(numOfRuns)\n",
    "\n",
    "                # Logistic Regression for reduced dataset\n",
    "                regr = LogisticRegression()                   \n",
    "                clf2 = regr.fit(X_trainNew, y_trainNew)\n",
    "                y_predNew = clf2.predict(X_testNew)\n",
    "                scoreLRRed = clf2.score(X_testNew, y_testNew)\n",
    "                LRaccuracy.append(scoreLRRed)  \n",
    "                cfm_LR = confusion_matrix(y_testNew, y_predNew, labels=[0,1])\n",
    "\n",
    "                # Calculate sensitivity\n",
    "                sensitivityLR = cfm_LR[1,1]/(cfm_LR[1,0]+cfm_LR[1,1])\n",
    "                LRsensitivity.append(sensitivityLR)\n",
    "\n",
    "                # Calculate Specificity\n",
    "                specificityLR = cfm_LR[0,0]/(cfm_LR[0,0]+cfm_LR[0,1])\n",
    "                LRspecificity.append(specificityLR)\n",
    "\n",
    "                # Calculate Precision\n",
    "                precisionLR = precision_score(y_testNew,y_predNew,average='weighted')\n",
    "                LRprecision.append(precisionLR)\n",
    "\n",
    "                # Calculate f-measure\n",
    "                fmeasureLR = f1_score(y_testNew,y_predNew,average='weighted')\n",
    "                LRfmeasure.append(fmeasureLR)\n",
    "\n",
    "                # Naive Bayes for reduced dataset\n",
    "                modelRed = GaussianNB()\n",
    "\n",
    "                # Train the model using the training sets \n",
    "                modelRed.fit(X_trainNew, y_trainNew)\n",
    "\n",
    "                #Predict Output \n",
    "                predictedRed = modelRed.predict(X_testNew)\n",
    "                scoreNBRed = accuracy_score(y_testNew, predictedRed)\n",
    "                NBaccuracy.append(scoreNBRed)\n",
    "\n",
    "                channelNum.append(ch)\n",
    "                Threshold.append(fr)\n",
    "\n",
    "                cfm_NB = confusion_matrix(y_testNew, predictedRed, labels=[0,1])\n",
    "                # Calculate sensitivity\n",
    "                sensitivityNB = cfm_NB[1,1]/(cfm_NB[1,0]+cfm_NB[1,1])\n",
    "                NBsensitivity.append(sensitivityNB)\n",
    "\n",
    "                # Calculate Specificity\n",
    "                specificityNB = cfm_NB[0,0]/(cfm_NB[0,0]+cfm_NB[0,1])\n",
    "                NBspecificity.append(specificityNB)\n",
    "\n",
    "                # Calculate Precision\n",
    "                precisionNB = precision_score(y_testNew,predictedRed,average='weighted')\n",
    "                NBprecision.append(precisionNB)\n",
    "\n",
    "                # Calculate f-measure\n",
    "                fmeasureNB = f1_score(y_testNew,predictedRed,average='weighted')\n",
    "                NBfmeasure.append(fmeasureNB)\n",
    "\n",
    "            numOfRuns = numOfRuns + 1\n",
    "        # Add the data to the csv\n",
    "        plc_df = pd.DataFrame({'Channel': channelNum,'Threshold': Threshold,  \n",
    "                               'NumCount':NumCount, 'Fold': FoldCount, \n",
    "                               'LRaccuracy':LRaccuracy, 'NBaccuracy': NBaccuracy,\n",
    "                               'LRsensitivity':LRsensitivity,'NBsensitivity':NBsensitivity, \n",
    "                               'LRspecificity':LRspecificity,'NBspecificity':NBspecificity,\n",
    "                               'LRprecision': LRprecision, 'NBprecision':NBprecision,\n",
    "                               'NBfmeasure':NBfmeasure, 'LRfmeasure':LRfmeasure\n",
    "                              })\n",
    "        plc_df.to_csv(Resultpath+'Output-6hours.csv', header=False,sep='\\t', encoding='utf-8', index=False, mode = 'a')\n",
    "        #print(plc_df)\n",
    "#    if (len(LRaccuracy) > 0 & len(NBaccuracy) > 0):\n",
    "p = stats.ttest_ind(LRaccuracy,NBaccuracy)\n",
    "#print(p[1])\n",
    "pValue.append(p[1])\n",
    "#print(pValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_plc = pd.read_csv(Resultpath+'Output-6hours.csv', header=1, sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_plc.columns = ['Channel','Fold','LRaccuracy', 'LRfmeasure', \n",
    "                    'LRprecision', 'LRsensitivity', 'LRspecificity', \n",
    "                    'NBaccuracy',' NBfmeasure', 'NBsensitivity',\n",
    "                    'NBspecificity','NBprecision',\n",
    "                    'NumCount', 'Threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Fold</th>\n",
       "      <th>LRaccuracy</th>\n",
       "      <th>LRfmeasure</th>\n",
       "      <th>LRprecision</th>\n",
       "      <th>LRsensitivity</th>\n",
       "      <th>LRspecificity</th>\n",
       "      <th>NBaccuracy</th>\n",
       "      <th>NBfmeasure</th>\n",
       "      <th>NBsensitivity</th>\n",
       "      <th>NBspecificity</th>\n",
       "      <th>NBprecision</th>\n",
       "      <th>NumCount</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15540</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15540</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15540</td>\n",
       "      <td>5</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15540</td>\n",
       "      <td>7</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Fold  LRaccuracy  LRfmeasure  LRprecision  LRsensitivity  \\\n",
       "0    15540     3    1.000000    1.000000     1.000000            NaN   \n",
       "1    15540     4    1.000000    1.000000     1.000000            NaN   \n",
       "2    15540     5    0.818182    0.900000     1.000000            NaN   \n",
       "3    15540     6    1.000000    1.000000     1.000000            NaN   \n",
       "4    15540     7    0.909091    0.865801     0.826446            0.0   \n",
       "\n",
       "   LRspecificity  NBaccuracy   NBfmeasure  NBsensitivity  NBspecificity  \\\n",
       "0       1.000000    1.000000     1.000000       1.000000            NaN   \n",
       "1       1.000000    0.833333     0.909091       1.000000            NaN   \n",
       "2       0.818182    0.727273     0.842105       1.000000            NaN   \n",
       "3       1.000000    1.000000     1.000000       1.000000            NaN   \n",
       "4       1.000000    0.909091     0.865801       0.826446            0.0   \n",
       "\n",
       "   NBprecision  NumCount  Threshold  \n",
       "0     1.000000         1         80  \n",
       "1     0.833333         1         80  \n",
       "2     0.727273         1         80  \n",
       "3     1.000000         1         80  \n",
       "4     1.000000         1         80  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_plc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_plc = read_plc.drop('NumCount', 1)\n",
    "read_plc = read_plc.drop('Fold', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ExtendedResultsDF = read_plc.groupby(['Channel','Threshold']).mean().add_suffix('_avg').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>LRaccuracy_avg</th>\n",
       "      <th>LRfmeasure_avg</th>\n",
       "      <th>LRprecision_avg</th>\n",
       "      <th>LRsensitivity_avg</th>\n",
       "      <th>LRspecificity_avg</th>\n",
       "      <th>NBaccuracy_avg</th>\n",
       "      <th>NBfmeasure_avg</th>\n",
       "      <th>NBsensitivity_avg</th>\n",
       "      <th>NBspecificity_avg</th>\n",
       "      <th>NBprecision_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1370</td>\n",
       "      <td>80</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.904618</td>\n",
       "      <td>0.895422</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.978409</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.903146</td>\n",
       "      <td>0.948323</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.880455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2340</td>\n",
       "      <td>80</td>\n",
       "      <td>0.762879</td>\n",
       "      <td>0.746727</td>\n",
       "      <td>0.754543</td>\n",
       "      <td>0.248148</td>\n",
       "      <td>0.889949</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.719677</td>\n",
       "      <td>0.747828</td>\n",
       "      <td>0.285185</td>\n",
       "      <td>0.820267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10670</td>\n",
       "      <td>80</td>\n",
       "      <td>0.964394</td>\n",
       "      <td>0.964502</td>\n",
       "      <td>0.973199</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.973384</td>\n",
       "      <td>0.978636</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.985714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10930</td>\n",
       "      <td>80</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.919749</td>\n",
       "      <td>0.932795</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.899643</td>\n",
       "      <td>0.937879</td>\n",
       "      <td>0.937840</td>\n",
       "      <td>0.948481</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.924643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11710</td>\n",
       "      <td>80</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.991725</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.991608</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Threshold  LRaccuracy_avg  LRfmeasure_avg  LRprecision_avg  \\\n",
       "0     1370         80        0.920455        0.904618         0.895422   \n",
       "1     2340         80        0.762879        0.746727         0.754543   \n",
       "2    10670         80        0.964394        0.964502         0.973199   \n",
       "3    10930         80        0.920455        0.919749         0.932795   \n",
       "4    11710         80        0.991667        0.991725         0.993056   \n",
       "\n",
       "   LRsensitivity_avg  LRspecificity_avg  NBaccuracy_avg   NBfmeasure_avg  \\\n",
       "0           0.416667           0.978409        0.875000         0.903146   \n",
       "1           0.248148           0.889949        0.718182         0.719677   \n",
       "2           0.960714           0.971429        0.972727         0.973384   \n",
       "3           0.943333           0.899643        0.937879         0.937840   \n",
       "4           0.985714           1.000000        0.991667         0.991608   \n",
       "\n",
       "   NBsensitivity_avg  NBspecificity_avg  NBprecision_avg  \n",
       "0           0.948323           0.861111         0.880455  \n",
       "1           0.747828           0.285185         0.820267  \n",
       "2           0.978636           0.973214         0.985714  \n",
       "3           0.948481           0.955000         0.924643  \n",
       "4           0.992857           1.000000         0.983333  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtendedResultsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above table indicates average of performance measure per Threshold per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the results to a CSV\n",
    "ExtendedResultsDF.to_csv(Resultpath+'ExtendedResults-6hours.csv', header=False,sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a subset copy with two columns: channels and threshold\n",
    "ExtendedResultsDFTemp = ExtendedResultsDF[['Channel', 'Threshold']] \n",
    "\n",
    "# count the number of channels in each threshold\n",
    "ExtendedResultsDFTemp = ExtendedResultsDFTemp.groupby(['Threshold']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_plc = read_plc.drop('Channel', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CompactResultsDF = read_plc.groupby(['Threshold']).mean().add_suffix('_avg').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inner join channels\n",
    "CompactResultsDFFinal = pd.merge(CompactResultsDF,ExtendedResultsDFTemp, on=['Threshold','Threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CompactResultsDFFinal['TimeResolution'] = '6hours'\n",
    "CompactResultsDFFinal['pValue'] = p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>LRaccuracy_avg</th>\n",
       "      <th>LRfmeasure_avg</th>\n",
       "      <th>LRprecision_avg</th>\n",
       "      <th>LRsensitivity_avg</th>\n",
       "      <th>LRspecificity_avg</th>\n",
       "      <th>NBaccuracy_avg</th>\n",
       "      <th>NBfmeasure_avg</th>\n",
       "      <th>NBsensitivity_avg</th>\n",
       "      <th>NBspecificity_avg</th>\n",
       "      <th>NBprecision_avg</th>\n",
       "      <th>Channel</th>\n",
       "      <th>TimeResolution</th>\n",
       "      <th>pValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>0.855949</td>\n",
       "      <td>0.842205</td>\n",
       "      <td>0.849854</td>\n",
       "      <td>0.673719</td>\n",
       "      <td>0.837692</td>\n",
       "      <td>0.832254</td>\n",
       "      <td>0.83304</td>\n",
       "      <td>0.859188</td>\n",
       "      <td>0.720364</td>\n",
       "      <td>0.818288</td>\n",
       "      <td>75</td>\n",
       "      <td>6hours</td>\n",
       "      <td>0.001142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  LRaccuracy_avg  LRfmeasure_avg  LRprecision_avg  \\\n",
       "0         80        0.855949        0.842205         0.849854   \n",
       "\n",
       "   LRsensitivity_avg  LRspecificity_avg  NBaccuracy_avg   NBfmeasure_avg  \\\n",
       "0           0.673719           0.837692        0.832254          0.83304   \n",
       "\n",
       "   NBsensitivity_avg  NBspecificity_avg  NBprecision_avg  Channel  \\\n",
       "0           0.859188           0.720364         0.818288       75   \n",
       "\n",
       "  TimeResolution    pValue  \n",
       "0         6hours  0.001142  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompactResultsDFFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the results to a CSV\n",
    "CompactResultsDFFinal.to_csv(Resultpath+'CompactResults-Baseline.csv', header=False,sep='\\t', index=False, mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
